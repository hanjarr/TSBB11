<!DOCTYPW html>
<html>
	<head>
		<title>Cartomatic</title>
		<meta charset = "utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		
		<link rel="stylesheet" type="text/css" href="CartomaticWeb.css">
		
		<script src="http://code.jquery.com/jquery-1.11.3.min.js"></script>
		<script src="CartomaticWeb.js"></script>
	</head>
	<body>
		<header>
			<div class="oneThird">
				<a href="#aboutDiv" class="headerBtn" id="aboutBtn">ABOUT</a>
				<a href="#homeDiv" class="headerBtn" id="homeBtn">HOME</a>
			</div>
			<div class="oneThird">
				<p class="headerLogo"></p>
			</div>
			<div class="oneThird">
				<a href="#resultDiv" class="headerBtn">RESULT</a>
				<a href="#documentDiv" class="headerBtn">DOCUMENTS</a>
			</div>
		</header>
		
		<div class="allDiv" id="homeDiv"> <!--HOME-->
			<div class="textDiv">
				<h1> Welcome to Cartomatic </h1>
				<h2> Your automated map reader</h2>
				<hr>
				<p>Every military officer or rescue leader know that in order to fastly organize and structure large operations you need good maps. This can sometimes be hard to come by, for example if the environment is a war zone or just after a catastrophy - flooding, avalanche or earthquake - where the surroundings dramatically has changed. With today’s satellites it is possible to get hold of large area images, but this is not always good enough. They can be hard to interpret - and primarily - they need to be interpreted. </p><br>
				<p>Cartomatic offers you a way to automatically create maps from these satellite images, which allows you to quick and easy see what roads are operational, and how to in the best way get from point A to B. A quick response in situations like war or disaster are the key to save lives! </p><br>
				<p>Our maps are created with cutting edge machine learning technology which allows you access to up to date maps in an instance. The software is easy to use so you can focus on what is important. </p><br>
			</div>
			
			<div id="homeImage" class="imageDiv"></div>
			
		</div>
		
		<div class="allDiv" id="aboutDiv"> <!--ABOUT-->
			<div class="textDiv">
				<h1>US</h1>
				<hr>
				<p>The project group consists of six students at Linköpings University</p><br>
				<p id = "p3"class="members"> Karin Stacke</p>
				<p id = "p6"class="members"> Joakim Svensk</p>
				<p id = "p2"class="members"> HannesBananes </p>
				<p id = "p4"class="members"> Gustav Tapper</p>
				<p id = "p0"class="members"> Boris Hård</p>
				<p id = "p5"class="members"> Sara Shimekaw</p>
				<p id = "p1"class="members"> Patrik Tosteberg</p>
				<br><br>
				<h1>PROJECT</h1>
				<hr>
				<p>With today's technology it is possible to get very high resolution images of the entire earth. This data could be used to create very accurate and up-to-date maps. Creating these maps by hand would be very time consuming and the demand of up-to-date would not be met. There is therfore a need for an automated classification system. 
				<br> Vricon is an international company that developes photo realistic 3D maps of the globe based on satellite images. OpenStreetMap (OSM) is an open-source project that allows private users from all over the world to add geographic information.</p>
			</div>
			
			<div id="aboutImage" class="imageDiv"></div>
		</div>
		
		<div class="allDiv" id="resultDiv"> <!--RESULT-->
			<div class="textDiv">
				<h1>Better then the expected</h1>
				<hr>
				<p>The confidence output from the network and post-processed classification max blended with the original for two test images are shown in Figure 3. Red represents background (BCC), green water (WCC) and blue roads (RCC). The accuracies for the classification max image (UL) were BCC: 73.3 % , WCC: 90.7 % and RCC: 73.1 %. After post-processing the accuracies were ramped up to BCC: 82.9 %, WCC: 94.5 % and RCC: 76.7 % (UR). The second test image contains no water and more distinct roads. The accuracies of the classification max were BCC: 76.4 % and RCC: 89.2 % (LL). The accuracies were ramped up to BCC: 85.6 % and RCC: 96.4 % after post-processing (LR).
				</p>
				<br><br>
				<h1> System Overview</h1>
				<hr>
				<p>The input data to the neural network consists of different features that are extracted from satellite images provided by Vricon. Ground truth data was generated from OSM, containing the relevant information (i.e. roads and water). After sufficient training, the network is tested on a different satellite image to generate a resulting classification and evaluate the systems accuracy. 
					<br><br>Features were extracted by dividing the input image into small pixel blocks and calculating different measures that depend on the cocurences of pixel pairs. This was done for each color band (RGB, NIR and PAN). Figure 2 shows the features extracted from the green band that gave the best classification results.
					<br><br>A post-processing step is performed on the classification image in order to improve on the result further. The aim of this last step is to remove isolated pixels of classes that most likely are misclassified.
				</p>
			</div>
			
			<div id="fourImages">
				<div id="imOne" class="oneOfFour"></div>
				<div id="imTwo" class="oneOfFour"></div>
				<div id="imThree" class="oneOfFour"></div>
				<div id="imFour" class="oneOfFour"></div>
			</div>
			
		</div>
		
		<div class="allDiv" id="documentDiv"> <!--DOCUMENTS-->
			<div class="textDiv">
				<h1>DOCUMENTS</h1>
				<hr>
				<br><h2>Downloads:</h2>
				<a href="ProjectPlan1_0.pdf" target="_blank">Technical report</a>
				<br>
				<a href="ProjectPlan1_0.pdf" target="_blank">Project Plan</a>
				<br>
				<a href="Projectspecification 0.2.pdf" target="_blank">Project Specification</a>
				<br>
				<a href="Projectspecification 0.2.pdf" target="_blank">Requirement Specification</a>
				<br>
				<a href="Projectspecification 0.2.pdf" target="_blank">Product Manual</a>
			</div>
		</div>
		
		<!--<footer>
		</footer>-->
	</body>
</html>						